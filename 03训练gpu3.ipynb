{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((687636, 2600), (76405, 2600))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "import numpy as np\n",
    "traval_tra_features = np.load('traval_tra_features.npy').astype(np.float32)\n",
    "traval_tra_targets = np.load('traval_tra_targets.npy').astype(np.int64)[:,0]\n",
    "traval_val_features = np.load('traval_val_features.npy').astype(np.float32)\n",
    "traval_val_targets = np.load('traval_val_targets.npy').astype(np.int64)[:,0]\n",
    "traval_tra_features.shape, traval_val_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from skorch import NeuralNetClassifier\n",
    "import sklearn\n",
    "from skorch.callbacks import EpochScoring, LRScheduler, Checkpoint\n",
    "from torch.optim import Adam, SGD\n",
    "import adamod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.dataset import Dataset\n",
    "from skorch.helper import predefined_split\n",
    "valid_ds = Dataset(traval_val_features, traval_val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSample2x(nn.Sequential):\n",
    "    def __init__(self, _in, _out):\n",
    "        super().__init__(\n",
    "            nn.Conv1d(_in, _out, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, _in, _hidden=64):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(_in, _hidden),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(_hidden, _in),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y\n",
    "    \n",
    "class ResConv1d(nn.Module):\n",
    "    def __init__(self, _in, _out):\n",
    "        super(ResConv1d, self).__init__()\n",
    "        \n",
    "        self.cal = nn.Sequential(\n",
    "            nn.Conv1d(_in, _out, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm1d(_out),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(_out, _out, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm1d(_out),\n",
    "        )\n",
    "        self.se = SELayer(_out, _out)\n",
    "        self.conv = nn.Conv1d(_in, _out, kernel_size=1, padding=0, stride=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn = nn.BatchNorm1d(_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = self.cal(x)\n",
    "        res = self.se(res)\n",
    "        \n",
    "        x = self.bn(self.conv(x))\n",
    "        \n",
    "        return self.relu(res + x)\n",
    "        \n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self, nonlin=F.relu):\n",
    "        super(MyModule, self).__init__()\n",
    "        \n",
    "        self.d1 = DownSample2x(1, 64)\n",
    "        self.c1 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.d2 = DownSample2x(64, 64)\n",
    "        self.c2 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.d3 = DownSample2x(64, 64)\n",
    "        self.c3 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.d4 = DownSample2x(64, 64)\n",
    "        self.c4 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.d5 = DownSample2x(64, 64)\n",
    "        self.c5 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.d6 = DownSample2x(64, 64)\n",
    "        self.c6 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.cls = nn.Linear(64 * 40, 3)\n",
    "        \n",
    "    def preprocess(self, x, p=2, eps=1e-8):\n",
    "        x = x / (x.norm(p=p, dim=1, keepdim=True)+eps)\n",
    "        x = x.unsqueeze(1)\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.size(0)\n",
    "        x = self.preprocess(x)\n",
    "        \n",
    "        x = self.d1(x)\n",
    "        x = self.c1(x)\n",
    "        \n",
    "        x = self.d2(x)\n",
    "        x = self.c2(x)\n",
    "        \n",
    "        x = self.d3(x)\n",
    "        x = self.c3(x)\n",
    "\n",
    "        x = self.d4(x)\n",
    "        x = self.c4(x)\n",
    "        \n",
    "        x = self.d5(x)\n",
    "        x = self.c5(x)\n",
    "        \n",
    "        x = self.d6(x)\n",
    "        x = self.c6(x)\n",
    "        \n",
    "        x = x.reshape(bs, -1)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return F.softmax(self.cls(x))\n",
    "\n",
    "    \n",
    "def microf1(net, ds, y=None):\n",
    "    y_true = [y for _, y in ds]\n",
    "    y_pred = net.predict(ds)\n",
    "    return sklearn.metrics.f1_score(y_true, y_pred,average='micro')\n",
    "def macrof1(net, ds, y=None):\n",
    "    y_true = [y for _, y in ds]\n",
    "    y_pred = net.predict(ds)\n",
    "    return sklearn.metrics.f1_score(y_true, y_pred,average='macro')\n",
    "\n",
    "class F1Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(F1Loss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target, eps=1e-10):\n",
    "        loss = 0\n",
    "        for idx, i in enumerate(torch.eye(3).cuda()):\n",
    "            t = i.view(3,1)\n",
    "            y_pred_ = input.matmul(t).squeeze()\n",
    "            y_true_ = target==idx\n",
    "            loss += 0.5 * (y_true_ * y_pred_).sum() / (y_true_ + y_pred_ + eps).sum()\n",
    "        return -torch.log(loss+eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9673\u001b[0m     \u001b[32m0.9919\u001b[0m        \u001b[35m0.0338\u001b[0m       \u001b[31m0.9919\u001b[0m        \u001b[94m0.0258\u001b[0m     +  307.5992\n",
      "      2     0.9139     0.9763        \u001b[35m0.0203\u001b[0m       0.9763        0.0726        310.0884\n",
      "      3     \u001b[36m0.9788\u001b[0m     \u001b[32m0.9945\u001b[0m        \u001b[35m0.0177\u001b[0m       \u001b[31m0.9945\u001b[0m        \u001b[94m0.0184\u001b[0m     +  306.0065\n",
      "      4     \u001b[36m0.9789\u001b[0m     \u001b[32m0.9946\u001b[0m        \u001b[35m0.0161\u001b[0m       \u001b[31m0.9946\u001b[0m        0.0186     +  304.8534\n",
      "      5     0.9789     \u001b[32m0.9948\u001b[0m        \u001b[35m0.0150\u001b[0m       \u001b[31m0.9948\u001b[0m        \u001b[94m0.0171\u001b[0m        305.3079\n",
      "      6     \u001b[36m0.9826\u001b[0m     \u001b[32m0.9957\u001b[0m        \u001b[35m0.0144\u001b[0m       \u001b[31m0.9957\u001b[0m        \u001b[94m0.0144\u001b[0m     +  304.0510\n",
      "      7     0.9809     0.9951        \u001b[35m0.0137\u001b[0m       0.9951        0.0155        303.9848\n",
      "      8     \u001b[36m0.9829\u001b[0m     \u001b[32m0.9957\u001b[0m        \u001b[35m0.0131\u001b[0m       \u001b[31m0.9957\u001b[0m        \u001b[94m0.0141\u001b[0m     +  303.1474\n",
      "      9     0.9812     0.9949        \u001b[35m0.0125\u001b[0m       0.9949        0.0174        302.1176\n",
      "     10     0.9779     0.9947        \u001b[35m0.0119\u001b[0m       0.9947        0.0165        301.1236\n",
      "     11     \u001b[36m0.9834\u001b[0m     \u001b[32m0.9958\u001b[0m        \u001b[35m0.0116\u001b[0m       \u001b[31m0.9958\u001b[0m        \u001b[94m0.0138\u001b[0m     +  301.2969\n",
      "     12     \u001b[36m0.9835\u001b[0m     \u001b[32m0.9958\u001b[0m        \u001b[35m0.0112\u001b[0m       \u001b[31m0.9958\u001b[0m        0.0143     +  301.6684\n",
      "     13     0.9822     0.9956        \u001b[35m0.0108\u001b[0m       0.9956        \u001b[94m0.0137\u001b[0m        304.7025\n",
      "     14     0.9818     0.9954        \u001b[35m0.0102\u001b[0m       0.9954        0.0150        306.2380\n",
      "     15     0.9826     0.9957        \u001b[35m0.0100\u001b[0m       0.9957        0.0148        306.2254\n",
      "     16     0.9821     0.9955        \u001b[35m0.0097\u001b[0m       0.9955        0.0152        305.7603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (d1): DownSample2x(\n",
       "      (0): Conv1d(1, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c1): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d2): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c2): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d3): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c3): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d4): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c4): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d5): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c5): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d6): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c6): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cls): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=16,\n",
    "    lr=0.001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model31')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.fit(traval_tra_features, traval_tra_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MacroLoss Fintuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9837\u001b[0m     \u001b[32m0.9960\u001b[0m        \u001b[35m0.3042\u001b[0m       \u001b[31m0.9960\u001b[0m        \u001b[94m0.3096\u001b[0m     +  312.0657\n",
      "      2     \u001b[36m0.9840\u001b[0m     \u001b[32m0.9961\u001b[0m        \u001b[35m0.3023\u001b[0m       \u001b[31m0.9961\u001b[0m        \u001b[94m0.3095\u001b[0m     +  312.1629\n",
      "      3     \u001b[36m0.9845\u001b[0m     \u001b[32m0.9961\u001b[0m        \u001b[35m0.3023\u001b[0m       \u001b[31m0.9961\u001b[0m        \u001b[94m0.3090\u001b[0m     +  311.5738\n",
      "      4     \u001b[36m0.9846\u001b[0m     \u001b[32m0.9962\u001b[0m        \u001b[35m0.3016\u001b[0m       \u001b[31m0.9962\u001b[0m        \u001b[94m0.3088\u001b[0m     +  313.2576\n",
      "      5     0.9844     0.9961        0.3016       0.9961        0.3090        312.6374\n",
      "      6     0.9842     0.9961        \u001b[35m0.3002\u001b[0m       0.9961        0.3095        311.8045\n",
      "      7     0.9836     0.9960        0.3003       0.9960        0.3100        312.5994\n",
      "      8     0.9836     0.9959        0.3004       0.9959        0.3096        310.8952\n",
      "      9     0.9843     0.9961        0.3009       0.9961        0.3093        312.1927\n",
      "     10     0.9836     0.9960        \u001b[35m0.2996\u001b[0m       0.9960        0.3095        310.9140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (d1): DownSample2x(\n",
       "      (0): Conv1d(1, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c1): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d2): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c2): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d3): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c3): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d4): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c4): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d5): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c5): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d6): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c6): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cls): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.0001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    criterion=F1Loss,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model31', fn_prefix='f1')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.initialize() \n",
    "net.load_params(f_params='03_model31/params.pt')\n",
    "net.partial_fit(traval_tra_features, traval_tra_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9672\u001b[0m     \u001b[32m0.9917\u001b[0m        \u001b[35m0.0344\u001b[0m       \u001b[31m0.9917\u001b[0m        \u001b[94m0.0269\u001b[0m     +  305.1364\n",
      "      2     \u001b[36m0.9807\u001b[0m     \u001b[32m0.9950\u001b[0m        \u001b[35m0.0203\u001b[0m       \u001b[31m0.9950\u001b[0m        \u001b[94m0.0172\u001b[0m     +  306.0134\n",
      "      3     0.9799     0.9949        \u001b[35m0.0177\u001b[0m       0.9949        \u001b[94m0.0168\u001b[0m        306.2343\n",
      "      4     0.9784     0.9949        \u001b[35m0.0161\u001b[0m       0.9949        \u001b[94m0.0158\u001b[0m        306.6969\n",
      "      5     0.9801     \u001b[32m0.9952\u001b[0m        \u001b[35m0.0150\u001b[0m       \u001b[31m0.9952\u001b[0m        \u001b[94m0.0152\u001b[0m        305.8357\n",
      "      6     0.9804     0.9951        \u001b[35m0.0144\u001b[0m       0.9951        0.0154        305.5180\n",
      "      7     \u001b[36m0.9811\u001b[0m     \u001b[32m0.9953\u001b[0m        \u001b[35m0.0137\u001b[0m       \u001b[31m0.9953\u001b[0m        0.0158     +  304.8416\n",
      "      8     \u001b[36m0.9832\u001b[0m     \u001b[32m0.9955\u001b[0m        \u001b[35m0.0129\u001b[0m       \u001b[31m0.9955\u001b[0m        0.0156     +  305.2161\n",
      "      9     0.9807     0.9954        \u001b[35m0.0126\u001b[0m       0.9954        0.0153        306.0027\n",
      "     10     \u001b[36m0.9838\u001b[0m     \u001b[32m0.9959\u001b[0m        \u001b[35m0.0120\u001b[0m       \u001b[31m0.9959\u001b[0m        \u001b[94m0.0140\u001b[0m     +  307.0037\n",
      "     11     0.9833     \u001b[32m0.9959\u001b[0m        \u001b[35m0.0116\u001b[0m       \u001b[31m0.9959\u001b[0m        \u001b[94m0.0138\u001b[0m        306.2909\n",
      "     12     0.9834     0.9959        \u001b[35m0.0112\u001b[0m       0.9959        0.0143        304.4764\n",
      "     13     0.9827     0.9957        \u001b[35m0.0108\u001b[0m       0.9957        0.0149        305.5698\n",
      "     14     \u001b[36m0.9839\u001b[0m     \u001b[32m0.9960\u001b[0m        \u001b[35m0.0104\u001b[0m       \u001b[31m0.9960\u001b[0m        0.0141     +  305.3983\n",
      "     15     0.9833     0.9959        \u001b[35m0.0100\u001b[0m       0.9959        0.0142        304.5379\n",
      "     16     0.9835     0.9960        \u001b[35m0.0096\u001b[0m       0.9960        0.0149        305.6634\n",
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9846\u001b[0m     \u001b[32m0.9962\u001b[0m        \u001b[35m0.3047\u001b[0m       \u001b[31m0.9962\u001b[0m        \u001b[94m0.3092\u001b[0m     +  308.5194\n",
      "      2     \u001b[36m0.9848\u001b[0m     \u001b[32m0.9962\u001b[0m        \u001b[35m0.3018\u001b[0m       \u001b[31m0.9962\u001b[0m        \u001b[94m0.3083\u001b[0m     +  308.8932\n",
      "      3     0.9848     \u001b[32m0.9962\u001b[0m        \u001b[35m0.3008\u001b[0m       \u001b[31m0.9962\u001b[0m        0.3088        312.0299\n",
      "      4     0.9842     0.9961        0.3011       0.9961        0.3092        311.6499\n",
      "      5     0.9839     0.9961        \u001b[35m0.3005\u001b[0m       0.9961        0.3093        310.8691\n",
      "      6     0.9841     0.9961        \u001b[35m0.3003\u001b[0m       0.9961        0.3094        306.7714\n",
      "      7     0.9843     0.9961        \u001b[35m0.3001\u001b[0m       0.9961        0.3090        306.5858\n",
      "      8     0.9839     0.9960        \u001b[35m0.3001\u001b[0m       0.9960        0.3093        307.0855\n",
      "      9     0.9845     0.9961        \u001b[35m0.2989\u001b[0m       0.9961        0.3085        307.9188\n",
      "     10     0.9840     0.9961        0.2989       0.9961        0.3090        309.8551\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (d1): DownSample2x(\n",
       "      (0): Conv1d(1, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c1): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d2): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c2): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d3): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c3): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d4): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c4): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d5): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c5): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d6): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c6): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cls): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=16,\n",
    "    lr=0.001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model32')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.fit(traval_tra_features, traval_tra_targets)\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.0001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    criterion=F1Loss,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model32', fn_prefix='f1')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.initialize() \n",
    "net.load_params(f_params='03_model32/params.pt')\n",
    "net.partial_fit(traval_tra_features, traval_tra_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9026\u001b[0m     \u001b[32m0.9767\u001b[0m        \u001b[35m0.0341\u001b[0m       \u001b[31m0.9767\u001b[0m        \u001b[94m0.0699\u001b[0m     +  302.4418\n",
      "      2     \u001b[36m0.9780\u001b[0m     \u001b[32m0.9944\u001b[0m        \u001b[35m0.0206\u001b[0m       \u001b[31m0.9944\u001b[0m        \u001b[94m0.0179\u001b[0m     +  303.2581\n",
      "      3     0.9775     0.9943        \u001b[35m0.0175\u001b[0m       0.9943        0.0194        301.4525\n",
      "      4     \u001b[36m0.9811\u001b[0m     \u001b[32m0.9954\u001b[0m        \u001b[35m0.0162\u001b[0m       \u001b[31m0.9954\u001b[0m        \u001b[94m0.0151\u001b[0m     +  302.0274\n",
      "      5     0.9799     0.9949        \u001b[35m0.0152\u001b[0m       0.9949        0.0159        301.9294\n",
      "      6     0.9807     0.9951        \u001b[35m0.0143\u001b[0m       0.9951        0.0155        301.2386\n",
      "      7     \u001b[36m0.9821\u001b[0m     \u001b[32m0.9956\u001b[0m        \u001b[35m0.0137\u001b[0m       \u001b[31m0.9956\u001b[0m        0.0152     +  302.8372\n",
      "      8     0.9817     0.9954        \u001b[35m0.0132\u001b[0m       0.9954        0.0154        300.0040\n",
      "      9     0.9796     0.9952        \u001b[35m0.0126\u001b[0m       0.9952        0.0163        302.2090\n",
      "     10     0.9812     0.9955        \u001b[35m0.0121\u001b[0m       0.9955        0.0157        303.2071\n",
      "     11     \u001b[36m0.9826\u001b[0m     \u001b[32m0.9958\u001b[0m        \u001b[35m0.0118\u001b[0m       \u001b[31m0.9958\u001b[0m        0.0154     +  303.8929\n",
      "     12     \u001b[36m0.9829\u001b[0m     \u001b[32m0.9958\u001b[0m        \u001b[35m0.0113\u001b[0m       \u001b[31m0.9958\u001b[0m        \u001b[94m0.0141\u001b[0m     +  303.5429\n",
      "     13     0.9801     0.9952        \u001b[35m0.0110\u001b[0m       0.9952        0.0149        301.8632\n",
      "     14     0.9826     0.9958        \u001b[35m0.0105\u001b[0m       0.9958        0.0145        304.4518\n",
      "     15     0.9825     0.9957        \u001b[35m0.0102\u001b[0m       0.9957        0.0151        306.4700\n",
      "     16     0.9826     0.9957        \u001b[35m0.0098\u001b[0m       0.9957        0.0154        306.2251\n",
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9844\u001b[0m     \u001b[32m0.9961\u001b[0m        \u001b[35m0.3049\u001b[0m       \u001b[31m0.9961\u001b[0m        \u001b[94m0.3093\u001b[0m     +  311.2005\n",
      "      2     0.9836     0.9960        \u001b[35m0.3030\u001b[0m       0.9960        0.3102        311.7328\n",
      "      3     \u001b[36m0.9850\u001b[0m     \u001b[32m0.9963\u001b[0m        0.3036       \u001b[31m0.9963\u001b[0m        \u001b[94m0.3089\u001b[0m     +  311.5689\n",
      "      4     0.9848     0.9963        \u001b[35m0.3027\u001b[0m       0.9963        \u001b[94m0.3087\u001b[0m        311.0428\n",
      "      5     0.9838     0.9961        \u001b[35m0.3012\u001b[0m       0.9961        0.3091        311.8502\n",
      "      6     0.9847     0.9962        \u001b[35m0.3004\u001b[0m       0.9962        \u001b[94m0.3087\u001b[0m        311.5555\n",
      "      7     0.9844     0.9962        0.3008       0.9962        \u001b[94m0.3087\u001b[0m        311.4203\n",
      "      8     0.9843     0.9962        0.3006       0.9962        0.3087        311.6193\n",
      "      9     0.9843     0.9961        0.3007       0.9961        0.3089        312.0762\n",
      "     10     0.9846     0.9962        \u001b[35m0.3000\u001b[0m       0.9962        \u001b[94m0.3085\u001b[0m        311.1480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (d1): DownSample2x(\n",
       "      (0): Conv1d(1, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c1): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d2): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c2): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d3): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c3): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d4): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c4): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d5): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c5): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d6): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c6): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cls): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=16,\n",
    "    lr=0.001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model33')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.fit(traval_tra_features, traval_tra_targets)\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.0001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    criterion=F1Loss,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model33', fn_prefix='f1')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.initialize() \n",
    "net.load_params(f_params='03_model33/params.pt')\n",
    "net.partial_fit(traval_tra_features, traval_tra_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9726\u001b[0m     \u001b[32m0.9930\u001b[0m        \u001b[35m0.0346\u001b[0m       \u001b[31m0.9930\u001b[0m        \u001b[94m0.0232\u001b[0m     +  305.8387\n",
      "      2     \u001b[36m0.9739\u001b[0m     \u001b[32m0.9933\u001b[0m        \u001b[35m0.0204\u001b[0m       \u001b[31m0.9933\u001b[0m        \u001b[94m0.0221\u001b[0m     +  302.1640\n",
      "      3     \u001b[36m0.9776\u001b[0m     \u001b[32m0.9946\u001b[0m        \u001b[35m0.0178\u001b[0m       \u001b[31m0.9946\u001b[0m        \u001b[94m0.0194\u001b[0m     +  302.9010\n",
      "      4     0.9765     0.9946        \u001b[35m0.0161\u001b[0m       0.9946        \u001b[94m0.0182\u001b[0m        303.9640\n",
      "      5     \u001b[36m0.9825\u001b[0m     \u001b[32m0.9958\u001b[0m        \u001b[35m0.0149\u001b[0m       \u001b[31m0.9958\u001b[0m        \u001b[94m0.0139\u001b[0m     +  301.6424\n",
      "      6     \u001b[36m0.9826\u001b[0m     0.9956        \u001b[35m0.0142\u001b[0m       0.9956        0.0144     +  301.1953\n",
      "      7     0.9812     0.9955        \u001b[35m0.0136\u001b[0m       0.9955        0.0148        303.1717\n",
      "      8     0.9811     0.9953        \u001b[35m0.0130\u001b[0m       0.9953        0.0150        303.0298\n",
      "      9     \u001b[36m0.9833\u001b[0m     \u001b[32m0.9959\u001b[0m        \u001b[35m0.0123\u001b[0m       \u001b[31m0.9959\u001b[0m        \u001b[94m0.0136\u001b[0m     +  302.7733\n",
      "     10     0.9824     0.9957        \u001b[35m0.0120\u001b[0m       0.9957        0.0146        302.9458\n",
      "     11     \u001b[36m0.9837\u001b[0m     \u001b[32m0.9959\u001b[0m        \u001b[35m0.0116\u001b[0m       \u001b[31m0.9959\u001b[0m        0.0143     +  300.9256\n",
      "     12     0.9834     0.9958        \u001b[35m0.0111\u001b[0m       0.9958        0.0146        303.1205\n",
      "     13     0.9833     \u001b[32m0.9959\u001b[0m        \u001b[35m0.0107\u001b[0m       \u001b[31m0.9959\u001b[0m        0.0139        300.2250\n",
      "     14     0.9834     0.9959        \u001b[35m0.0103\u001b[0m       0.9959        0.0150        300.0296\n",
      "     15     0.9830     0.9958        \u001b[35m0.0099\u001b[0m       0.9958        0.0144        302.0889\n",
      "     16     0.9834     0.9958        \u001b[35m0.0096\u001b[0m       0.9958        0.0158        302.7859\n",
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9849\u001b[0m     \u001b[32m0.9963\u001b[0m        \u001b[35m0.3048\u001b[0m       \u001b[31m0.9963\u001b[0m        \u001b[94m0.3091\u001b[0m     +  308.1192\n",
      "      2     0.9839     0.9961        \u001b[35m0.3028\u001b[0m       0.9961        0.3098        308.1457\n",
      "      3     0.9845     0.9962        \u001b[35m0.3020\u001b[0m       0.9962        \u001b[94m0.3088\u001b[0m        307.2943\n",
      "      4     0.9845     0.9962        \u001b[35m0.3012\u001b[0m       0.9962        0.3095        307.4185\n",
      "      5     0.9844     0.9962        0.3012       0.9962        0.3089        306.6105\n",
      "      6     0.9840     0.9961        \u001b[35m0.3010\u001b[0m       0.9961        0.3091        307.4490\n",
      "      7     0.9843     0.9962        \u001b[35m0.3007\u001b[0m       0.9962        0.3096        307.4023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (d1): DownSample2x(\n",
       "      (0): Conv1d(1, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c1): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d2): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c2): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d3): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c3): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d4): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c4): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d5): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c5): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d6): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c6): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cls): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=16,\n",
    "    lr=0.001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model34')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.fit(traval_tra_features, traval_tra_targets)\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.0001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    criterion=F1Loss,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model34', fn_prefix='f1')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.initialize() \n",
    "net.load_params(f_params='03_model34/params.pt')\n",
    "net.partial_fit(traval_tra_features, traval_tra_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
