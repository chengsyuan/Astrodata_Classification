{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((687636, 2600), (76405, 2600))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "import numpy as np\n",
    "traval_tra_features = np.load('traval_tra_features.npy').astype(np.float32)\n",
    "traval_tra_targets = np.load('traval_tra_targets.npy').astype(np.int64)[:,0]\n",
    "traval_val_features = np.load('traval_val_features.npy').astype(np.float32)\n",
    "traval_val_targets = np.load('traval_val_targets.npy').astype(np.int64)[:,0]\n",
    "traval_tra_features.shape, traval_val_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from skorch import NeuralNetClassifier\n",
    "import sklearn\n",
    "from skorch.callbacks import EpochScoring, LRScheduler, Checkpoint\n",
    "from torch.optim import Adam, SGD\n",
    "import adamod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.dataset import Dataset\n",
    "from skorch.helper import predefined_split\n",
    "valid_ds = Dataset(traval_val_features, traval_val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSample2x(nn.Sequential):\n",
    "    def __init__(self, _in, _out):\n",
    "        super().__init__(\n",
    "            nn.Conv1d(_in, _out, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, _in, _hidden=64):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(_in, _hidden),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(_hidden, _in),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y\n",
    "    \n",
    "class ResConv1d(nn.Module):\n",
    "    def __init__(self, _in, _out):\n",
    "        super(ResConv1d, self).__init__()\n",
    "        \n",
    "        self.cal = nn.Sequential(\n",
    "            nn.Conv1d(_in, _out, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm1d(_out),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(_out, _out, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm1d(_out),\n",
    "        )\n",
    "        self.se = SELayer(_out, _out)\n",
    "        self.conv = nn.Conv1d(_in, _out, kernel_size=1, padding=0, stride=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn = nn.BatchNorm1d(_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = self.cal(x)\n",
    "        res = self.se(res)\n",
    "        \n",
    "        x = self.bn(self.conv(x))\n",
    "        \n",
    "        return self.relu(res + x)\n",
    "        \n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self, nonlin=F.relu):\n",
    "        super(MyModule, self).__init__()\n",
    "        \n",
    "        self.d1 = DownSample2x(1, 64)\n",
    "        self.c1 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.d2 = DownSample2x(64, 64)\n",
    "        self.c2 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.d3 = DownSample2x(64, 64)\n",
    "        self.c3 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.d4 = DownSample2x(64, 64)\n",
    "        self.c4 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.d5 = DownSample2x(64, 64)\n",
    "        self.c5 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.d6 = DownSample2x(64, 64)\n",
    "        self.c6 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.cls = nn.Linear(64 * 40, 3)\n",
    "        \n",
    "    def preprocess(self, x, p=2, eps=1e-8):\n",
    "        x = x / (x.norm(p=p, dim=1, keepdim=True)+eps)\n",
    "        x = x.unsqueeze(1)\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.size(0)\n",
    "        x = self.preprocess(x)\n",
    "        \n",
    "        x = self.d1(x)\n",
    "        x = self.c1(x)\n",
    "        \n",
    "        x = self.d2(x)\n",
    "        x = self.c2(x)\n",
    "        \n",
    "        x = self.d3(x)\n",
    "        x = self.c3(x)\n",
    "\n",
    "        x = self.d4(x)\n",
    "        x = self.c4(x)\n",
    "        \n",
    "        x = self.d5(x)\n",
    "        x = self.c5(x)\n",
    "        \n",
    "        x = self.d6(x)\n",
    "        x = self.c6(x)\n",
    "        \n",
    "        x = x.reshape(bs, -1)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return F.softmax(self.cls(x))\n",
    "\n",
    "    \n",
    "def microf1(net, ds, y=None):\n",
    "    y_true = [y for _, y in ds]\n",
    "    y_pred = net.predict(ds)\n",
    "    return sklearn.metrics.f1_score(y_true, y_pred,average='micro')\n",
    "def macrof1(net, ds, y=None):\n",
    "    y_true = [y for _, y in ds]\n",
    "    y_pred = net.predict(ds)\n",
    "    return sklearn.metrics.f1_score(y_true, y_pred,average='macro')\n",
    "\n",
    "class F1Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(F1Loss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target, eps=1e-10):\n",
    "        loss = 0\n",
    "        for idx, i in enumerate(torch.eye(3).cuda()):\n",
    "            t = i.view(3,1)\n",
    "            y_pred_ = input.matmul(t).squeeze()\n",
    "            y_true_ = target==idx\n",
    "            loss += 0.5 * (y_true_ * y_pred_).sum() / (y_true_ + y_pred_ + eps).sum()\n",
    "        return -torch.log(loss+eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9425\u001b[0m     \u001b[32m0.9727\u001b[0m        \u001b[35m0.0338\u001b[0m       \u001b[31m0.9727\u001b[0m        \u001b[94m0.0777\u001b[0m     +  301.9974\n",
      "      2     \u001b[36m0.9744\u001b[0m     \u001b[32m0.9940\u001b[0m        \u001b[35m0.0204\u001b[0m       \u001b[31m0.9940\u001b[0m        \u001b[94m0.0197\u001b[0m     +  304.2222\n",
      "      3     0.9657     0.9885        \u001b[35m0.0175\u001b[0m       0.9885        0.0371        305.2140\n",
      "      4     \u001b[36m0.9755\u001b[0m     0.9938        \u001b[35m0.0161\u001b[0m       0.9938        0.0203     +  306.2678\n",
      "      5     \u001b[36m0.9805\u001b[0m     \u001b[32m0.9948\u001b[0m        \u001b[35m0.0150\u001b[0m       \u001b[31m0.9948\u001b[0m        \u001b[94m0.0176\u001b[0m     +  305.3813\n",
      "      6     \u001b[36m0.9827\u001b[0m     \u001b[32m0.9958\u001b[0m        \u001b[35m0.0144\u001b[0m       \u001b[31m0.9958\u001b[0m        \u001b[94m0.0144\u001b[0m     +  311.1043\n",
      "      7     0.9808     0.9954        \u001b[35m0.0135\u001b[0m       0.9954        0.0148        306.7435\n",
      "      8     0.9826     0.9957        \u001b[35m0.0131\u001b[0m       0.9957        0.0147        305.9699\n",
      "      9     0.9822     0.9957        \u001b[35m0.0126\u001b[0m       0.9957        0.0148        305.2845\n",
      "     10     0.9817     0.9955        \u001b[35m0.0120\u001b[0m       0.9955        0.0149        303.0803\n",
      "     11     0.9814     0.9956        \u001b[35m0.0119\u001b[0m       0.9956        0.0148        302.6106\n",
      "     12     \u001b[36m0.9832\u001b[0m     \u001b[32m0.9958\u001b[0m        \u001b[35m0.0112\u001b[0m       \u001b[31m0.9958\u001b[0m        \u001b[94m0.0141\u001b[0m     +  301.4825\n",
      "     13     0.9824     0.9956        \u001b[35m0.0108\u001b[0m       0.9956        0.0149        302.7727\n",
      "     14     0.9828     0.9958        \u001b[35m0.0104\u001b[0m       0.9958        0.0146        302.0075\n",
      "     15     0.9832     0.9958        \u001b[35m0.0101\u001b[0m       0.9958        0.0144        302.6632\n",
      "     16     \u001b[36m0.9833\u001b[0m     \u001b[32m0.9959\u001b[0m        \u001b[35m0.0097\u001b[0m       \u001b[31m0.9959\u001b[0m        0.0141     +  301.2118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (d1): DownSample2x(\n",
       "      (0): Conv1d(1, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c1): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d2): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c2): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d3): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c3): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d4): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c4): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d5): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c5): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d6): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c6): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cls): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=16,\n",
    "    lr=0.001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model21')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.fit(traval_tra_features, traval_tra_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MacroLoss Fintuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9844\u001b[0m     \u001b[32m0.9962\u001b[0m        \u001b[35m0.3043\u001b[0m       \u001b[31m0.9962\u001b[0m        \u001b[94m0.3092\u001b[0m     +  303.6465\n",
      "      2     0.9838     0.9961        \u001b[35m0.3008\u001b[0m       0.9961        0.3092        304.9288\n",
      "      3     0.9841     0.9962        0.3012       0.9962        0.3093        302.6331\n",
      "      4     \u001b[36m0.9846\u001b[0m     \u001b[32m0.9962\u001b[0m        \u001b[35m0.3002\u001b[0m       \u001b[31m0.9962\u001b[0m        \u001b[94m0.3088\u001b[0m     +  307.6701\n",
      "      5     0.9840     0.9961        \u001b[35m0.2990\u001b[0m       0.9961        0.3099        308.2073\n",
      "      6     0.9837     0.9961        0.2996       0.9961        0.3098        305.5918\n",
      "      7     0.9843     0.9962        0.2997       0.9962        0.3096        304.3351\n",
      "      8     0.9842     0.9962        \u001b[35m0.2985\u001b[0m       0.9962        0.3096        302.8951\n",
      "      9     0.9841     0.9961        0.2991       0.9961        0.3095        306.0301\n",
      "     10     0.9843     0.9962        \u001b[35m0.2975\u001b[0m       0.9962        0.3093        303.5218\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (d1): DownSample2x(\n",
       "      (0): Conv1d(1, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c1): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d2): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c2): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d3): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c3): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d4): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c4): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d5): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c5): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d6): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c6): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cls): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.0001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    criterion=F1Loss,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model21', fn_prefix='f1')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.initialize() \n",
    "net.load_params(f_params='03_model21/params.pt')\n",
    "net.partial_fit(traval_tra_features, traval_tra_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9658\u001b[0m     \u001b[32m0.9913\u001b[0m        \u001b[35m0.0333\u001b[0m       \u001b[31m0.9913\u001b[0m        \u001b[94m0.0316\u001b[0m     +  297.0346\n",
      "      2     0.8987     0.9586        \u001b[35m0.0201\u001b[0m       0.9586        0.1227        298.8108\n",
      "      3     \u001b[36m0.9781\u001b[0m     \u001b[32m0.9940\u001b[0m        \u001b[35m0.0178\u001b[0m       \u001b[31m0.9940\u001b[0m        \u001b[94m0.0197\u001b[0m     +  297.9007\n",
      "      4     \u001b[36m0.9807\u001b[0m     \u001b[32m0.9953\u001b[0m        \u001b[35m0.0161\u001b[0m       \u001b[31m0.9953\u001b[0m        \u001b[94m0.0160\u001b[0m     +  298.7638\n",
      "      5     0.9798     0.9948        \u001b[35m0.0152\u001b[0m       0.9948        0.0171        297.4060\n",
      "      6     \u001b[36m0.9829\u001b[0m     \u001b[32m0.9956\u001b[0m        \u001b[35m0.0142\u001b[0m       \u001b[31m0.9956\u001b[0m        \u001b[94m0.0148\u001b[0m     +  297.7647\n",
      "      7     0.9814     0.9952        \u001b[35m0.0136\u001b[0m       0.9952        0.0157        297.2848\n",
      "      8     \u001b[36m0.9829\u001b[0m     \u001b[32m0.9957\u001b[0m        \u001b[35m0.0130\u001b[0m       \u001b[31m0.9957\u001b[0m        \u001b[94m0.0142\u001b[0m     +  299.7893\n",
      "      9     0.9810     0.9954        \u001b[35m0.0126\u001b[0m       0.9954        0.0159        299.1556\n",
      "     10     0.9823     0.9955        \u001b[35m0.0120\u001b[0m       0.9955        0.0153        297.8839\n",
      "     11     \u001b[36m0.9830\u001b[0m     \u001b[32m0.9958\u001b[0m        \u001b[35m0.0118\u001b[0m       \u001b[31m0.9958\u001b[0m        0.0146     +  296.9920\n",
      "     12     0.9815     0.9955        \u001b[35m0.0112\u001b[0m       0.9955        \u001b[94m0.0142\u001b[0m        295.7739\n",
      "     13     0.9816     0.9954        \u001b[35m0.0106\u001b[0m       0.9954        0.0149        296.2127\n",
      "     14     \u001b[36m0.9841\u001b[0m     \u001b[32m0.9960\u001b[0m        \u001b[35m0.0106\u001b[0m       \u001b[31m0.9960\u001b[0m        \u001b[94m0.0132\u001b[0m     +  297.0747\n",
      "     15     0.9822     0.9956        \u001b[35m0.0101\u001b[0m       0.9956        0.0150        297.3239\n",
      "     16     0.9831     0.9958        \u001b[35m0.0098\u001b[0m       0.9958        0.0142        299.1866\n",
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9852\u001b[0m     \u001b[32m0.9962\u001b[0m        \u001b[35m0.3041\u001b[0m       \u001b[31m0.9962\u001b[0m        \u001b[94m0.3087\u001b[0m     +  301.5919\n",
      "      2     0.9851     \u001b[32m0.9962\u001b[0m        \u001b[35m0.3021\u001b[0m       \u001b[31m0.9962\u001b[0m        0.3087        304.0179\n",
      "      3     0.9843     0.9961        0.3022       0.9961        0.3089        302.3345\n",
      "      4     0.9848     0.9962        \u001b[35m0.3006\u001b[0m       0.9962        0.3087        302.7483\n",
      "      5     0.9847     0.9962        0.3010       0.9962        \u001b[94m0.3086\u001b[0m        301.4613\n",
      "      6     0.9841     0.9961        \u001b[35m0.3003\u001b[0m       0.9961        0.3094        301.2100\n",
      "      7     0.9849     0.9962        \u001b[35m0.3002\u001b[0m       0.9962        0.3089        302.4128\n",
      "      8     0.9843     0.9961        \u001b[35m0.2988\u001b[0m       0.9961        0.3091        304.3123\n",
      "      9     0.9847     0.9962        0.2996       0.9962        0.3089        302.0332\n",
      "     10     0.9839     0.9960        0.2995       0.9960        0.3093        303.0924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (d1): DownSample2x(\n",
       "      (0): Conv1d(1, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c1): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d2): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c2): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d3): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c3): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d4): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c4): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d5): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c5): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d6): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c6): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cls): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=16,\n",
    "    lr=0.001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model22')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.fit(traval_tra_features, traval_tra_targets)\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.0001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    criterion=F1Loss,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model22', fn_prefix='f1')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.initialize() \n",
    "net.load_params(f_params='03_model22/params.pt')\n",
    "net.partial_fit(traval_tra_features, traval_tra_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9642\u001b[0m     \u001b[32m0.9884\u001b[0m        \u001b[35m0.0353\u001b[0m       \u001b[31m0.9884\u001b[0m        \u001b[94m0.0331\u001b[0m     +  299.1565\n",
      "      2     \u001b[36m0.9736\u001b[0m     \u001b[32m0.9934\u001b[0m        \u001b[35m0.0210\u001b[0m       \u001b[31m0.9934\u001b[0m        \u001b[94m0.0222\u001b[0m     +  295.6930\n",
      "      3     \u001b[36m0.9798\u001b[0m     \u001b[32m0.9950\u001b[0m        \u001b[35m0.0180\u001b[0m       \u001b[31m0.9950\u001b[0m        \u001b[94m0.0162\u001b[0m     +  302.4762\n",
      "      4     0.9794     0.9949        \u001b[35m0.0164\u001b[0m       0.9949        0.0167        302.3084\n",
      "      5     0.9788     0.9942        \u001b[35m0.0152\u001b[0m       0.9942        0.0180        302.4575\n",
      "      6     \u001b[36m0.9813\u001b[0m     \u001b[32m0.9953\u001b[0m        \u001b[35m0.0145\u001b[0m       \u001b[31m0.9953\u001b[0m        \u001b[94m0.0157\u001b[0m     +  304.5403\n",
      "      7     0.9773     0.9943        \u001b[35m0.0137\u001b[0m       0.9943        0.0179        301.1611\n",
      "      8     \u001b[36m0.9830\u001b[0m     \u001b[32m0.9957\u001b[0m        \u001b[35m0.0131\u001b[0m       \u001b[31m0.9957\u001b[0m        \u001b[94m0.0145\u001b[0m     +  302.4969\n",
      "      9     0.9824     0.9957        \u001b[35m0.0126\u001b[0m       0.9957        \u001b[94m0.0138\u001b[0m        302.1068\n",
      "     10     0.9815     0.9956        \u001b[35m0.0122\u001b[0m       0.9956        0.0153        304.1788\n",
      "     11     0.9821     0.9957        \u001b[35m0.0119\u001b[0m       0.9957        0.0142        303.7525\n",
      "     12     \u001b[36m0.9833\u001b[0m     \u001b[32m0.9959\u001b[0m        \u001b[35m0.0115\u001b[0m       \u001b[31m0.9959\u001b[0m        0.0147     +  303.0303\n",
      "     13     0.9831     0.9958        \u001b[35m0.0110\u001b[0m       0.9958        0.0149        302.8776\n",
      "     14     0.9814     0.9955        \u001b[35m0.0108\u001b[0m       0.9955        0.0158        304.6177\n",
      "     15     0.9818     0.9956        \u001b[35m0.0104\u001b[0m       0.9956        0.0148        302.7848\n",
      "     16     0.9830     0.9959        \u001b[35m0.0099\u001b[0m       0.9959        0.0144        307.5835\n",
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9842\u001b[0m     \u001b[32m0.9961\u001b[0m        \u001b[35m0.3056\u001b[0m       \u001b[31m0.9961\u001b[0m        \u001b[94m0.3098\u001b[0m     +  310.1327\n",
      "      2     0.9840     0.9961        \u001b[35m0.3026\u001b[0m       0.9961        \u001b[94m0.3096\u001b[0m        307.9296\n",
      "      3     0.9839     0.9960        0.3036       0.9960        0.3097        309.7965\n",
      "      4     \u001b[36m0.9845\u001b[0m     \u001b[32m0.9962\u001b[0m        \u001b[35m0.3022\u001b[0m       \u001b[31m0.9962\u001b[0m        \u001b[94m0.3090\u001b[0m     +  307.4323\n",
      "      5     0.9841     0.9961        \u001b[35m0.3017\u001b[0m       0.9961        \u001b[94m0.3087\u001b[0m        305.4441\n",
      "      6     0.9843     0.9962        \u001b[35m0.3011\u001b[0m       0.9962        0.3092        307.3449\n",
      "      7     \u001b[36m0.9848\u001b[0m     \u001b[32m0.9963\u001b[0m        \u001b[35m0.3004\u001b[0m       \u001b[31m0.9963\u001b[0m        \u001b[94m0.3083\u001b[0m     +  307.4179\n",
      "      8     0.9838     0.9961        \u001b[35m0.2995\u001b[0m       0.9961        0.3087        307.6498\n",
      "      9     0.9843     0.9962        0.3010       0.9962        0.3090        310.4499\n",
      "     10     0.9843     0.9961        0.2996       0.9961        0.3092        314.5120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (d1): DownSample2x(\n",
       "      (0): Conv1d(1, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c1): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d2): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c2): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d3): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c3): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d4): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c4): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d5): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c5): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d6): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c6): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cls): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=16,\n",
    "    lr=0.001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model23')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.fit(traval_tra_features, traval_tra_targets)\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.0001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    criterion=F1Loss,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model23', fn_prefix='f1')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.initialize() \n",
    "net.load_params(f_params='03_model23/params.pt')\n",
    "net.partial_fit(traval_tra_features, traval_tra_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9386\u001b[0m     \u001b[32m0.9795\u001b[0m        \u001b[35m0.0346\u001b[0m       \u001b[31m0.9795\u001b[0m        \u001b[94m0.0720\u001b[0m     +  305.8630\n",
      "      2     \u001b[36m0.9658\u001b[0m     \u001b[32m0.9921\u001b[0m        \u001b[35m0.0202\u001b[0m       \u001b[31m0.9921\u001b[0m        \u001b[94m0.0247\u001b[0m     +  306.2593\n",
      "      3     \u001b[36m0.9737\u001b[0m     \u001b[32m0.9932\u001b[0m        \u001b[35m0.0178\u001b[0m       \u001b[31m0.9932\u001b[0m        \u001b[94m0.0213\u001b[0m     +  303.1106\n",
      "      4     \u001b[36m0.9803\u001b[0m     \u001b[32m0.9950\u001b[0m        \u001b[35m0.0161\u001b[0m       \u001b[31m0.9950\u001b[0m        \u001b[94m0.0163\u001b[0m     +  306.3297\n",
      "      5     \u001b[36m0.9820\u001b[0m     \u001b[32m0.9956\u001b[0m        \u001b[35m0.0151\u001b[0m       \u001b[31m0.9956\u001b[0m        \u001b[94m0.0146\u001b[0m     +  303.5151\n",
      "      6     \u001b[36m0.9826\u001b[0m     \u001b[32m0.9957\u001b[0m        \u001b[35m0.0144\u001b[0m       \u001b[31m0.9957\u001b[0m        \u001b[94m0.0143\u001b[0m     +  302.1786\n",
      "      7     0.9824     0.9955        \u001b[35m0.0135\u001b[0m       0.9955        0.0149        303.5883\n",
      "      8     0.9786     0.9947        \u001b[35m0.0131\u001b[0m       0.9947        0.0158        303.9847\n",
      "      9     \u001b[36m0.9835\u001b[0m     \u001b[32m0.9959\u001b[0m        \u001b[35m0.0126\u001b[0m       \u001b[31m0.9959\u001b[0m        \u001b[94m0.0143\u001b[0m     +  303.6690\n",
      "     10     0.9833     0.9958        \u001b[35m0.0120\u001b[0m       0.9958        \u001b[94m0.0139\u001b[0m        302.8309\n",
      "     11     \u001b[36m0.9840\u001b[0m     0.9959        \u001b[35m0.0117\u001b[0m       0.9959        0.0142     +  303.4676\n",
      "     12     0.9834     0.9959        \u001b[35m0.0112\u001b[0m       0.9959        0.0147        303.9460\n",
      "     13     0.9801     0.9952        \u001b[35m0.0108\u001b[0m       0.9952        0.0161        302.1378\n",
      "     14     0.9803     0.9951        \u001b[35m0.0105\u001b[0m       0.9951        0.0166        301.5353\n",
      "     15     0.9823     0.9956        \u001b[35m0.0102\u001b[0m       0.9956        0.0151        302.4948\n",
      "     16     0.9825     0.9957        \u001b[35m0.0097\u001b[0m       0.9957        0.0149        302.7817\n",
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9852\u001b[0m     \u001b[32m0.9963\u001b[0m        \u001b[35m0.3059\u001b[0m       \u001b[31m0.9963\u001b[0m        \u001b[94m0.3090\u001b[0m     +  309.6763\n",
      "      2     0.9850     0.9962        \u001b[35m0.3033\u001b[0m       0.9962        \u001b[94m0.3088\u001b[0m        309.0531\n",
      "      3     0.9851     0.9962        0.3034       0.9962        \u001b[94m0.3086\u001b[0m        311.2864\n",
      "      4     0.9845     0.9962        \u001b[35m0.3016\u001b[0m       0.9962        0.3088        310.4022\n",
      "      5     0.9848     0.9963        0.3019       0.9963        \u001b[94m0.3085\u001b[0m        309.0044\n",
      "      6     0.9843     0.9961        \u001b[35m0.3009\u001b[0m       0.9961        0.3092        308.8025\n",
      "      7     0.9843     0.9961        0.3015       0.9961        0.3092        308.4257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (d1): DownSample2x(\n",
       "      (0): Conv1d(1, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c1): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d2): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c2): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d3): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c3): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d4): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c4): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d5): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c5): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d6): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c6): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cls): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=16,\n",
    "    lr=0.001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model24')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.fit(traval_tra_features, traval_tra_targets)\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.0001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    criterion=F1Loss,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model24', fn_prefix='f1')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.initialize() \n",
    "net.load_params(f_params='03_model24/params.pt')\n",
    "net.partial_fit(traval_tra_features, traval_tra_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
