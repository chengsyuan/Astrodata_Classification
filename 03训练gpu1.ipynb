{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((687636, 2600), (76405, 2600))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import numpy as np\n",
    "traval_tra_features = np.load('traval_tra_features.npy').astype(np.float32)\n",
    "traval_tra_targets = np.load('traval_tra_targets.npy').astype(np.int64)[:,0]\n",
    "traval_val_features = np.load('traval_val_features.npy').astype(np.float32)\n",
    "traval_val_targets = np.load('traval_val_targets.npy').astype(np.int64)[:,0]\n",
    "traval_tra_features.shape, traval_val_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from skorch import NeuralNetClassifier\n",
    "import sklearn\n",
    "from skorch.callbacks import EpochScoring, LRScheduler, Checkpoint\n",
    "from torch.optim import Adam, SGD\n",
    "import adamod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.dataset import Dataset\n",
    "from skorch.helper import predefined_split\n",
    "valid_ds = Dataset(traval_val_features, traval_val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSample2x(nn.Sequential):\n",
    "    def __init__(self, _in, _out):\n",
    "        super().__init__(\n",
    "            nn.Conv1d(_in, _out, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, _in, _hidden=64):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(_in, _hidden),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(_hidden, _in),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y\n",
    "    \n",
    "class ResConv1d(nn.Module):\n",
    "    def __init__(self, _in, _out):\n",
    "        super(ResConv1d, self).__init__()\n",
    "        \n",
    "        self.cal = nn.Sequential(\n",
    "            nn.Conv1d(_in, _out, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm1d(_out),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(_out, _out, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm1d(_out),\n",
    "        )\n",
    "        self.se = SELayer(_out, _out)\n",
    "        self.conv = nn.Conv1d(_in, _out, kernel_size=1, padding=0, stride=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn = nn.BatchNorm1d(_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = self.cal(x)\n",
    "        res = self.se(res)\n",
    "        \n",
    "        x = self.bn(self.conv(x))\n",
    "        \n",
    "        return self.relu(res + x)\n",
    "        \n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self, nonlin=F.relu):\n",
    "        super(MyModule, self).__init__()\n",
    "        \n",
    "        self.d1 = DownSample2x(1, 64)\n",
    "        self.c1 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.d2 = DownSample2x(64, 64)\n",
    "        self.c2 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.d3 = DownSample2x(64, 64)\n",
    "        self.c3 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.d4 = DownSample2x(64, 64)\n",
    "        self.c4 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.d5 = DownSample2x(64, 64)\n",
    "        self.c5 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.d6 = DownSample2x(64, 64)\n",
    "        self.c6 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.cls = nn.Linear(64 * 40, 3)\n",
    "        \n",
    "    def preprocess(self, x, p=2, eps=1e-8):\n",
    "        x = x / (x.norm(p=p, dim=1, keepdim=True)+eps)\n",
    "        x = x.unsqueeze(1)\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.size(0)\n",
    "        x = self.preprocess(x)\n",
    "        \n",
    "        x = self.d1(x)\n",
    "        x = self.c1(x)\n",
    "        \n",
    "        x = self.d2(x)\n",
    "        x = self.c2(x)\n",
    "        \n",
    "        x = self.d3(x)\n",
    "        x = self.c3(x)\n",
    "\n",
    "        x = self.d4(x)\n",
    "        x = self.c4(x)\n",
    "        \n",
    "        x = self.d5(x)\n",
    "        x = self.c5(x)\n",
    "        \n",
    "        x = self.d6(x)\n",
    "        x = self.c6(x)\n",
    "        \n",
    "        x = x.reshape(bs, -1)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return F.softmax(self.cls(x))\n",
    "\n",
    "    \n",
    "def microf1(net, ds, y=None):\n",
    "    y_true = [y for _, y in ds]\n",
    "    y_pred = net.predict(ds)\n",
    "    return sklearn.metrics.f1_score(y_true, y_pred,average='micro')\n",
    "def macrof1(net, ds, y=None):\n",
    "    y_true = [y for _, y in ds]\n",
    "    y_pred = net.predict(ds)\n",
    "    return sklearn.metrics.f1_score(y_true, y_pred,average='macro')\n",
    "\n",
    "class F1Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(F1Loss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target, eps=1e-10):\n",
    "        loss = 0\n",
    "        for idx, i in enumerate(torch.eye(3).cuda()):\n",
    "            t = i.view(3,1)\n",
    "            y_pred_ = input.matmul(t).squeeze()\n",
    "            y_true_ = target==idx\n",
    "            loss += 0.5 * (y_true_ * y_pred_).sum() / (y_true_ + y_pred_ + eps).sum()\n",
    "        return -torch.log(loss+eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9652\u001b[0m     \u001b[32m0.9908\u001b[0m        \u001b[35m0.0342\u001b[0m       \u001b[31m0.9908\u001b[0m        \u001b[94m0.0298\u001b[0m     +  305.2410\n",
      "      2     \u001b[36m0.9780\u001b[0m     \u001b[32m0.9940\u001b[0m        \u001b[35m0.0205\u001b[0m       \u001b[31m0.9940\u001b[0m        \u001b[94m0.0193\u001b[0m     +  305.7516\n",
      "      3     \u001b[36m0.9789\u001b[0m     \u001b[32m0.9946\u001b[0m        \u001b[35m0.0177\u001b[0m       \u001b[31m0.9946\u001b[0m        \u001b[94m0.0174\u001b[0m     +  305.0816\n",
      "      4     \u001b[36m0.9821\u001b[0m     \u001b[32m0.9954\u001b[0m        \u001b[35m0.0159\u001b[0m       \u001b[31m0.9954\u001b[0m        \u001b[94m0.0148\u001b[0m     +  305.0066\n",
      "      5     0.9818     0.9954        \u001b[35m0.0150\u001b[0m       0.9954        0.0151        304.3461\n",
      "      6     0.9820     \u001b[32m0.9956\u001b[0m        \u001b[35m0.0144\u001b[0m       \u001b[31m0.9956\u001b[0m        0.0150        304.3996\n",
      "      7     0.9807     0.9954        \u001b[35m0.0136\u001b[0m       0.9954        \u001b[94m0.0146\u001b[0m        304.5651\n",
      "      8     0.9818     0.9953        \u001b[35m0.0130\u001b[0m       0.9953        0.0162        304.4427\n",
      "      9     \u001b[36m0.9830\u001b[0m     \u001b[32m0.9958\u001b[0m        \u001b[35m0.0125\u001b[0m       \u001b[31m0.9958\u001b[0m        \u001b[94m0.0144\u001b[0m     +  303.8449\n",
      "     10     \u001b[36m0.9837\u001b[0m     \u001b[32m0.9960\u001b[0m        \u001b[35m0.0120\u001b[0m       \u001b[31m0.9960\u001b[0m        \u001b[94m0.0135\u001b[0m     +  303.3929\n",
      "     11     0.9827     0.9958        \u001b[35m0.0117\u001b[0m       0.9958        0.0147        303.9138\n",
      "     12     0.9822     0.9958        \u001b[35m0.0112\u001b[0m       0.9958        0.0142        305.4176\n",
      "     13     0.9822     0.9957        \u001b[35m0.0108\u001b[0m       0.9957        0.0146        306.7686\n",
      "     14     \u001b[36m0.9837\u001b[0m     0.9959        \u001b[35m0.0104\u001b[0m       0.9959        0.0144     +  306.5422\n",
      "     15     0.9818     0.9956        \u001b[35m0.0103\u001b[0m       0.9956        0.0144        306.6838\n",
      "     16     0.9830     0.9958        \u001b[35m0.0098\u001b[0m       0.9958        0.0146        305.5992\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (d1): DownSample2x(\n",
       "      (0): Conv1d(1, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c1): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d2): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c2): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d3): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c3): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d4): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c4): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d5): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c5): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d6): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c6): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cls): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=16,\n",
    "    lr=0.001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model11')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.fit(traval_tra_features, traval_tra_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MacroLoss Fintuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9841\u001b[0m     \u001b[32m0.9961\u001b[0m        \u001b[35m0.3046\u001b[0m       \u001b[31m0.9961\u001b[0m        \u001b[94m0.3086\u001b[0m     +  313.4550\n",
      "      2     \u001b[36m0.9843\u001b[0m     \u001b[32m0.9962\u001b[0m        \u001b[35m0.3020\u001b[0m       \u001b[31m0.9962\u001b[0m        \u001b[94m0.3085\u001b[0m     +  312.7837\n",
      "      3     \u001b[36m0.9846\u001b[0m     \u001b[32m0.9962\u001b[0m        \u001b[35m0.3009\u001b[0m       \u001b[31m0.9962\u001b[0m        \u001b[94m0.3084\u001b[0m     +  312.8702\n",
      "      4     \u001b[36m0.9846\u001b[0m     0.9962        \u001b[35m0.3004\u001b[0m       0.9962        \u001b[94m0.3081\u001b[0m     +  312.5561\n",
      "      5     0.9842     0.9962        0.3009       0.9962        0.3086        312.9365\n",
      "      6     0.9840     0.9961        0.3004       0.9961        0.3089        312.1712\n",
      "      7     0.9839     0.9961        0.3005       0.9961        0.3085        313.2180\n",
      "      8     0.9843     0.9962        \u001b[35m0.2996\u001b[0m       0.9962        0.3083        313.4552\n",
      "      9     0.9842     0.9962        \u001b[35m0.2990\u001b[0m       0.9962        0.3083        316.8708\n",
      "     10     0.9844     0.9962        0.2998       0.9962        0.3082        308.3700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (d1): DownSample2x(\n",
       "      (0): Conv1d(1, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c1): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d2): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c2): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d3): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c3): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d4): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c4): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d5): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c5): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d6): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c6): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cls): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.0001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    criterion=F1Loss,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model11', fn_prefix='f1')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.initialize() \n",
    "net.load_params(f_params='03_model11/params.pt')\n",
    "net.partial_fit(traval_tra_features, traval_tra_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9461\u001b[0m     \u001b[32m0.9853\u001b[0m        \u001b[35m0.0337\u001b[0m       \u001b[31m0.9853\u001b[0m        \u001b[94m0.0451\u001b[0m     +  304.6923\n",
      "      2     \u001b[36m0.9726\u001b[0m     \u001b[32m0.9921\u001b[0m        \u001b[35m0.0203\u001b[0m       \u001b[31m0.9921\u001b[0m        \u001b[94m0.0247\u001b[0m     +  300.5658\n",
      "      3     \u001b[36m0.9785\u001b[0m     \u001b[32m0.9947\u001b[0m        \u001b[35m0.0176\u001b[0m       \u001b[31m0.9947\u001b[0m        \u001b[94m0.0171\u001b[0m     +  301.8805\n",
      "      4     \u001b[36m0.9791\u001b[0m     \u001b[32m0.9948\u001b[0m        \u001b[35m0.0161\u001b[0m       \u001b[31m0.9948\u001b[0m        0.0172     +  300.6212\n",
      "      5     \u001b[36m0.9806\u001b[0m     \u001b[32m0.9951\u001b[0m        \u001b[35m0.0151\u001b[0m       \u001b[31m0.9951\u001b[0m        \u001b[94m0.0161\u001b[0m     +  297.3172\n",
      "      6     \u001b[36m0.9816\u001b[0m     \u001b[32m0.9952\u001b[0m        \u001b[35m0.0144\u001b[0m       \u001b[31m0.9952\u001b[0m        \u001b[94m0.0159\u001b[0m     +  300.2840\n",
      "      7     \u001b[36m0.9818\u001b[0m     0.9951        \u001b[35m0.0136\u001b[0m       0.9951        0.0169     +  302.4204\n",
      "      8     \u001b[36m0.9820\u001b[0m     \u001b[32m0.9957\u001b[0m        \u001b[35m0.0131\u001b[0m       \u001b[31m0.9957\u001b[0m        \u001b[94m0.0147\u001b[0m     +  297.5359\n",
      "      9     \u001b[36m0.9825\u001b[0m     0.9955        \u001b[35m0.0126\u001b[0m       0.9955        0.0152     +  302.3985\n",
      "     10     \u001b[36m0.9827\u001b[0m     \u001b[32m0.9958\u001b[0m        \u001b[35m0.0121\u001b[0m       \u001b[31m0.9958\u001b[0m        \u001b[94m0.0143\u001b[0m     +  298.5416\n",
      "     11     0.9825     0.9956        \u001b[35m0.0117\u001b[0m       0.9956        \u001b[94m0.0142\u001b[0m        304.0059\n",
      "     12     0.9822     0.9957        \u001b[35m0.0114\u001b[0m       0.9957        \u001b[94m0.0135\u001b[0m        299.5346\n",
      "     13     \u001b[36m0.9829\u001b[0m     0.9956        \u001b[35m0.0110\u001b[0m       0.9956        0.0145     +  302.5282\n",
      "     14     \u001b[36m0.9836\u001b[0m     \u001b[32m0.9960\u001b[0m        \u001b[35m0.0106\u001b[0m       \u001b[31m0.9960\u001b[0m        0.0141     +  298.7489\n",
      "     15     0.9832     0.9959        \u001b[35m0.0101\u001b[0m       0.9959        0.0146        302.9613\n",
      "     16     0.9823     0.9956        \u001b[35m0.0099\u001b[0m       0.9956        0.0143        304.8575\n",
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9848\u001b[0m     \u001b[32m0.9963\u001b[0m        \u001b[35m0.3045\u001b[0m       \u001b[31m0.9963\u001b[0m        \u001b[94m0.3089\u001b[0m     +  309.8074\n",
      "      2     0.9848     \u001b[32m0.9963\u001b[0m        \u001b[35m0.3031\u001b[0m       \u001b[31m0.9963\u001b[0m        \u001b[94m0.3086\u001b[0m        308.3955\n",
      "      3     \u001b[36m0.9850\u001b[0m     \u001b[32m0.9963\u001b[0m        \u001b[35m0.3016\u001b[0m       \u001b[31m0.9963\u001b[0m        \u001b[94m0.3081\u001b[0m     +  305.6457\n",
      "      4     0.9844     0.9962        \u001b[35m0.3007\u001b[0m       0.9962        0.3086        316.9213\n",
      "      5     0.9846     0.9962        \u001b[35m0.3002\u001b[0m       0.9962        0.3087        317.0876\n",
      "      6     0.9844     0.9962        0.3021       0.9962        0.3089        316.5336\n",
      "      7     0.9844     0.9962        \u001b[35m0.3000\u001b[0m       0.9962        0.3087        310.6024\n",
      "      8     0.9848     0.9962        \u001b[35m0.2998\u001b[0m       0.9962        0.3081        305.7429\n",
      "      9     0.9843     0.9962        \u001b[35m0.2991\u001b[0m       0.9962        0.3087        305.1452\n",
      "     10     0.9844     0.9961        0.2995       0.9961        0.3087        306.3799\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (d1): DownSample2x(\n",
       "      (0): Conv1d(1, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c1): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d2): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c2): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d3): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c3): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d4): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c4): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d5): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c5): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d6): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c6): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cls): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=16,\n",
    "    lr=0.001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model12')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.fit(traval_tra_features, traval_tra_targets)\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.0001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    criterion=F1Loss,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model12', fn_prefix='f1')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.initialize() \n",
    "net.load_params(f_params='03_model12/params.pt')\n",
    "net.partial_fit(traval_tra_features, traval_tra_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9718\u001b[0m     \u001b[32m0.9923\u001b[0m        \u001b[35m0.0338\u001b[0m       \u001b[31m0.9923\u001b[0m        \u001b[94m0.0241\u001b[0m     +  301.0853\n",
      "      2     \u001b[36m0.9722\u001b[0m     \u001b[32m0.9930\u001b[0m        \u001b[35m0.0205\u001b[0m       \u001b[31m0.9930\u001b[0m        \u001b[94m0.0219\u001b[0m     +  302.4394\n",
      "      3     \u001b[36m0.9803\u001b[0m     \u001b[32m0.9949\u001b[0m        \u001b[35m0.0177\u001b[0m       \u001b[31m0.9949\u001b[0m        \u001b[94m0.0171\u001b[0m     +  302.6816\n",
      "      4     \u001b[36m0.9814\u001b[0m     \u001b[32m0.9951\u001b[0m        \u001b[35m0.0162\u001b[0m       \u001b[31m0.9951\u001b[0m        \u001b[94m0.0160\u001b[0m     +  301.5645\n",
      "      5     0.9811     \u001b[32m0.9954\u001b[0m        \u001b[35m0.0151\u001b[0m       \u001b[31m0.9954\u001b[0m        \u001b[94m0.0156\u001b[0m        301.1116\n",
      "      6     \u001b[36m0.9832\u001b[0m     \u001b[32m0.9956\u001b[0m        \u001b[35m0.0143\u001b[0m       \u001b[31m0.9956\u001b[0m        \u001b[94m0.0148\u001b[0m     +  303.1260\n",
      "      7     0.9830     \u001b[32m0.9957\u001b[0m        \u001b[35m0.0136\u001b[0m       \u001b[31m0.9957\u001b[0m        0.0153        302.2166\n",
      "      8     0.9813     0.9955        \u001b[35m0.0130\u001b[0m       0.9955        0.0157        309.7902\n",
      "      9     0.9790     0.9950        \u001b[35m0.0125\u001b[0m       0.9950        0.0160        298.5745\n",
      "     10     0.9829     \u001b[32m0.9958\u001b[0m        \u001b[35m0.0123\u001b[0m       \u001b[31m0.9958\u001b[0m        \u001b[94m0.0143\u001b[0m        301.5993\n",
      "     11     \u001b[36m0.9835\u001b[0m     \u001b[32m0.9960\u001b[0m        \u001b[35m0.0118\u001b[0m       \u001b[31m0.9960\u001b[0m        \u001b[94m0.0134\u001b[0m     +  300.3869\n",
      "     12     0.9825     0.9956        \u001b[35m0.0114\u001b[0m       0.9956        0.0145        308.7997\n",
      "     13     0.9829     0.9957        \u001b[35m0.0108\u001b[0m       0.9957        0.0157        301.1936\n",
      "     14     0.9820     0.9957        \u001b[35m0.0106\u001b[0m       0.9957        0.0155        306.0179\n",
      "     15     \u001b[36m0.9837\u001b[0m     0.9960        \u001b[35m0.0102\u001b[0m       0.9960        0.0139     +  303.4905\n",
      "     16     0.9834     0.9958        \u001b[35m0.0099\u001b[0m       0.9958        0.0145        301.8862\n",
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9851\u001b[0m     \u001b[32m0.9962\u001b[0m        \u001b[35m0.3036\u001b[0m       \u001b[31m0.9962\u001b[0m        \u001b[94m0.3091\u001b[0m     +  307.0287\n",
      "      2     0.9849     0.9962        \u001b[35m0.3016\u001b[0m       0.9962        0.3092        307.6260\n",
      "      3     0.9844     0.9961        0.3020       0.9961        \u001b[94m0.3089\u001b[0m        309.3976\n",
      "      4     0.9847     0.9961        \u001b[35m0.3009\u001b[0m       0.9961        0.3089        308.4438\n",
      "      5     0.9847     0.9962        \u001b[35m0.3000\u001b[0m       0.9962        \u001b[94m0.3085\u001b[0m        312.4115\n",
      "      6     0.9841     0.9960        0.3002       0.9960        0.3092        308.7453\n",
      "      7     0.9844     0.9960        \u001b[35m0.2998\u001b[0m       0.9960        0.3089        320.6692\n",
      "      8     0.9840     0.9960        \u001b[35m0.2989\u001b[0m       0.9960        0.3089        307.4550\n",
      "      9     0.9846     0.9962        0.2989       0.9962        0.3086        308.5827\n",
      "     10     0.9845     0.9961        \u001b[35m0.2985\u001b[0m       0.9961        0.3088        309.3796\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (d1): DownSample2x(\n",
       "      (0): Conv1d(1, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c1): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d2): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c2): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d3): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c3): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d4): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c4): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d5): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c5): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d6): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c6): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cls): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=16,\n",
    "    lr=0.001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model13')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.fit(traval_tra_features, traval_tra_targets)\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.0001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    criterion=F1Loss,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model13', fn_prefix='f1')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.initialize() \n",
    "net.load_params(f_params='03_model13/params.pt')\n",
    "net.partial_fit(traval_tra_features, traval_tra_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9675\u001b[0m     \u001b[32m0.9908\u001b[0m        \u001b[35m0.0332\u001b[0m       \u001b[31m0.9908\u001b[0m        \u001b[94m0.0306\u001b[0m     +  303.0650\n",
      "      2     \u001b[36m0.9749\u001b[0m     \u001b[32m0.9940\u001b[0m        \u001b[35m0.0203\u001b[0m       \u001b[31m0.9940\u001b[0m        \u001b[94m0.0190\u001b[0m     +  303.9570\n",
      "      3     \u001b[36m0.9796\u001b[0m     \u001b[32m0.9949\u001b[0m        \u001b[35m0.0176\u001b[0m       \u001b[31m0.9949\u001b[0m        \u001b[94m0.0164\u001b[0m     +  300.4302\n",
      "      4     0.9769     0.9940        \u001b[35m0.0161\u001b[0m       0.9940        0.0193        301.3334\n",
      "      5     \u001b[36m0.9800\u001b[0m     \u001b[32m0.9951\u001b[0m        \u001b[35m0.0151\u001b[0m       \u001b[31m0.9951\u001b[0m        \u001b[94m0.0158\u001b[0m     +  302.5114\n",
      "      6     \u001b[36m0.9815\u001b[0m     \u001b[32m0.9953\u001b[0m        \u001b[35m0.0144\u001b[0m       \u001b[31m0.9953\u001b[0m        \u001b[94m0.0156\u001b[0m     +  309.4205\n",
      "      7     0.9809     0.9952        \u001b[35m0.0136\u001b[0m       0.9952        0.0159        299.1623\n",
      "      8     0.9813     \u001b[32m0.9953\u001b[0m        \u001b[35m0.0130\u001b[0m       \u001b[31m0.9953\u001b[0m        \u001b[94m0.0154\u001b[0m        309.6056\n",
      "      9     \u001b[36m0.9822\u001b[0m     \u001b[32m0.9956\u001b[0m        \u001b[35m0.0126\u001b[0m       \u001b[31m0.9956\u001b[0m        0.0154     +  301.0174\n",
      "     10     \u001b[36m0.9830\u001b[0m     \u001b[32m0.9958\u001b[0m        \u001b[35m0.0123\u001b[0m       \u001b[31m0.9958\u001b[0m        \u001b[94m0.0142\u001b[0m     +  301.0730\n",
      "     11     \u001b[36m0.9838\u001b[0m     \u001b[32m0.9960\u001b[0m        \u001b[35m0.0117\u001b[0m       \u001b[31m0.9960\u001b[0m        \u001b[94m0.0142\u001b[0m     +  302.1005\n",
      "     12     0.9815     0.9952        \u001b[35m0.0114\u001b[0m       0.9952        0.0163        300.4592\n",
      "     13     0.9821     0.9957        \u001b[35m0.0110\u001b[0m       0.9957        0.0149        301.0314\n",
      "     14     0.9825     0.9957        \u001b[35m0.0105\u001b[0m       0.9957        0.0144        303.4098\n",
      "     15     0.9835     \u001b[32m0.9960\u001b[0m        \u001b[35m0.0100\u001b[0m       \u001b[31m0.9960\u001b[0m        0.0142        300.9236\n",
      "     16     0.9823     0.9956        \u001b[35m0.0097\u001b[0m       0.9956        0.0159        298.4390\n",
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9843\u001b[0m     \u001b[32m0.9962\u001b[0m        \u001b[35m0.3053\u001b[0m       \u001b[31m0.9962\u001b[0m        \u001b[94m0.3089\u001b[0m     +  306.7031\n",
      "      2     \u001b[36m0.9847\u001b[0m     \u001b[32m0.9963\u001b[0m        \u001b[35m0.3039\u001b[0m       \u001b[31m0.9963\u001b[0m        \u001b[94m0.3084\u001b[0m     +  302.8415\n",
      "      3     \u001b[36m0.9848\u001b[0m     0.9963        \u001b[35m0.3036\u001b[0m       0.9963        \u001b[94m0.3082\u001b[0m     +  309.9206\n",
      "      4     0.9845     0.9963        \u001b[35m0.3013\u001b[0m       0.9963        0.3089        307.2566\n",
      "      5     0.9839     0.9961        0.3017       0.9961        0.3092        306.0402\n",
      "      6     0.9847     0.9963        \u001b[35m0.3013\u001b[0m       0.9963        0.3087        309.3190\n",
      "      7     0.9840     0.9961        \u001b[35m0.3011\u001b[0m       0.9961        0.3090        313.1877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (d1): DownSample2x(\n",
       "      (0): Conv1d(1, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c1): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d2): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c2): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d3): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c3): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d4): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c4): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d5): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c5): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d6): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c6): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cls): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=16,\n",
    "    lr=0.001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model14')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.fit(traval_tra_features, traval_tra_targets)\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.0001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    criterion=F1Loss,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model14', fn_prefix='f1')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.initialize() \n",
    "net.load_params(f_params='03_model14/params.pt')\n",
    "net.partial_fit(traval_tra_features, traval_tra_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
