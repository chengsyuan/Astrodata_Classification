{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((687636, 2600), (76405, 2600))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import numpy as np\n",
    "traval_tra_features = np.load('traval_tra_features.npy').astype(np.float32)\n",
    "traval_tra_targets = np.load('traval_tra_targets.npy').astype(np.int64)[:,0]\n",
    "traval_val_features = np.load('traval_val_features.npy').astype(np.float32)\n",
    "traval_val_targets = np.load('traval_val_targets.npy').astype(np.int64)[:,0]\n",
    "traval_tra_features.shape, traval_val_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from skorch import NeuralNetClassifier\n",
    "import sklearn\n",
    "from skorch.callbacks import EpochScoring, LRScheduler, Checkpoint\n",
    "from torch.optim import Adam, SGD\n",
    "import adamod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.dataset import Dataset\n",
    "from skorch.helper import predefined_split\n",
    "valid_ds = Dataset(traval_val_features, traval_val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownSample2x(nn.Sequential):\n",
    "    def __init__(self, _in, _out):\n",
    "        super().__init__(\n",
    "            nn.Conv1d(_in, _out, kernel_size=2, stride=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "class SELayer(nn.Module):\n",
    "    def __init__(self, _in, _hidden=64):\n",
    "        super(SELayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(_in, _hidden),\n",
    "            nn.PReLU(),\n",
    "            nn.Linear(_hidden, _in),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1)\n",
    "        return x * y\n",
    "    \n",
    "class ResConv1d(nn.Module):\n",
    "    def __init__(self, _in, _out):\n",
    "        super(ResConv1d, self).__init__()\n",
    "        \n",
    "        self.cal = nn.Sequential(\n",
    "            nn.Conv1d(_in, _out, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm1d(_out),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(_out, _out, kernel_size=3, padding=1, stride=1),\n",
    "            nn.BatchNorm1d(_out),\n",
    "        )\n",
    "        self.se = SELayer(_out, _out)\n",
    "        self.conv = nn.Conv1d(_in, _out, kernel_size=1, padding=0, stride=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn = nn.BatchNorm1d(_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        res = self.cal(x)\n",
    "        res = self.se(res)\n",
    "        \n",
    "        x = self.bn(self.conv(x))\n",
    "        \n",
    "        return self.relu(res + x)\n",
    "        \n",
    "class MyModule(nn.Module):\n",
    "    def __init__(self, nonlin=F.relu):\n",
    "        super(MyModule, self).__init__()\n",
    "        \n",
    "        self.d1 = DownSample2x(1, 64)\n",
    "        self.c1 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.d2 = DownSample2x(64, 64)\n",
    "        self.c2 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.d3 = DownSample2x(64, 64)\n",
    "        self.c3 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.d4 = DownSample2x(64, 64)\n",
    "        self.c4 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.d5 = DownSample2x(64, 64)\n",
    "        self.c5 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.d6 = DownSample2x(64, 64)\n",
    "        self.c6 = ResConv1d(64, 64)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.cls = nn.Linear(64 * 40, 3)\n",
    "        \n",
    "    def preprocess(self, x, p=2, eps=1e-8):\n",
    "        x = x / (x.norm(p=p, dim=1, keepdim=True)+eps)\n",
    "        x = x.unsqueeze(1)\n",
    "        return x\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.size(0)\n",
    "        x = self.preprocess(x)\n",
    "        \n",
    "        x = self.d1(x)\n",
    "        x = self.c1(x)\n",
    "        \n",
    "        x = self.d2(x)\n",
    "        x = self.c2(x)\n",
    "        \n",
    "        x = self.d3(x)\n",
    "        x = self.c3(x)\n",
    "\n",
    "        x = self.d4(x)\n",
    "        x = self.c4(x)\n",
    "        \n",
    "        x = self.d5(x)\n",
    "        x = self.c5(x)\n",
    "        \n",
    "        x = self.d6(x)\n",
    "        x = self.c6(x)\n",
    "        \n",
    "        x = x.reshape(bs, -1)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return F.softmax(self.cls(x))\n",
    "\n",
    "    \n",
    "def microf1(net, ds, y=None):\n",
    "    y_true = [y for _, y in ds]\n",
    "    y_pred = net.predict(ds)\n",
    "    return sklearn.metrics.f1_score(y_true, y_pred,average='micro')\n",
    "def macrof1(net, ds, y=None):\n",
    "    y_true = [y for _, y in ds]\n",
    "    y_pred = net.predict(ds)\n",
    "    return sklearn.metrics.f1_score(y_true, y_pred,average='macro')\n",
    "\n",
    "class F1Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(F1Loss, self).__init__()\n",
    "\n",
    "    def forward(self, input, target, eps=1e-10):\n",
    "        loss = 0\n",
    "        for idx, i in enumerate(torch.eye(3).cuda()):\n",
    "            t = i.view(3,1)\n",
    "            y_pred_ = input.matmul(t).squeeze()\n",
    "            y_true_ = target==idx\n",
    "            loss += 0.5 * (y_true_ * y_pred_).sum() / (y_true_ + y_pred_ + eps).sum()\n",
    "        return -torch.log(loss+eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9666\u001b[0m     \u001b[32m0.9894\u001b[0m        \u001b[35m0.0340\u001b[0m       \u001b[31m0.9894\u001b[0m        \u001b[94m0.0356\u001b[0m     +  310.5964\n",
      "      2     0.9655     0.9891        \u001b[35m0.0203\u001b[0m       0.9891        \u001b[94m0.0343\u001b[0m        311.6362\n",
      "      3     \u001b[36m0.9789\u001b[0m     \u001b[32m0.9944\u001b[0m        \u001b[35m0.0176\u001b[0m       \u001b[31m0.9944\u001b[0m        \u001b[94m0.0190\u001b[0m     +  309.7627\n",
      "      4     0.9519     0.9881        \u001b[35m0.0161\u001b[0m       0.9881        0.0366        310.7354\n",
      "      5     \u001b[36m0.9790\u001b[0m     \u001b[32m0.9949\u001b[0m        \u001b[35m0.0151\u001b[0m       \u001b[31m0.9949\u001b[0m        \u001b[94m0.0163\u001b[0m     +  309.8077\n",
      "      6     \u001b[36m0.9804\u001b[0m     \u001b[32m0.9950\u001b[0m        \u001b[35m0.0142\u001b[0m       \u001b[31m0.9950\u001b[0m        \u001b[94m0.0157\u001b[0m     +  308.3822\n",
      "      7     \u001b[36m0.9805\u001b[0m     0.9950        \u001b[35m0.0138\u001b[0m       0.9950        0.0161     +  309.8312\n",
      "      8     \u001b[36m0.9837\u001b[0m     \u001b[32m0.9960\u001b[0m        \u001b[35m0.0131\u001b[0m       \u001b[31m0.9960\u001b[0m        \u001b[94m0.0137\u001b[0m     +  311.1483\n",
      "      9     0.9831     0.9956        \u001b[35m0.0126\u001b[0m       0.9956        0.0149        309.0915\n",
      "     10     0.9821     0.9956        \u001b[35m0.0121\u001b[0m       0.9956        0.0141        309.8035\n",
      "     11     0.9829     0.9958        \u001b[35m0.0117\u001b[0m       0.9958        0.0150        308.7333\n",
      "     12     0.9827     0.9954        \u001b[35m0.0112\u001b[0m       0.9954        0.0154        308.9272\n",
      "     13     0.9829     0.9958        \u001b[35m0.0109\u001b[0m       0.9958        0.0143        307.4850\n",
      "     14     0.9835     0.9958        \u001b[35m0.0105\u001b[0m       0.9958        0.0147        306.8247\n",
      "     15     0.9831     0.9959        \u001b[35m0.0102\u001b[0m       0.9959        \u001b[94m0.0137\u001b[0m        307.2473\n",
      "     16     0.9819     0.9956        \u001b[35m0.0098\u001b[0m       0.9956        0.0148        308.1865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (d1): DownSample2x(\n",
       "      (0): Conv1d(1, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c1): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d2): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c2): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d3): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c3): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d4): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c4): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d5): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c5): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d6): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c6): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cls): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=16,\n",
    "    lr=0.001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model1')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.fit(traval_tra_features, traval_tra_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MacroLoss Fintuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9844\u001b[0m     \u001b[32m0.9962\u001b[0m        \u001b[35m0.3072\u001b[0m       \u001b[31m0.9962\u001b[0m        \u001b[94m0.3091\u001b[0m     +  313.8841\n",
      "      2     0.9839     0.9960        \u001b[35m0.3046\u001b[0m       0.9960        0.3094        314.0102\n",
      "      3     \u001b[36m0.9847\u001b[0m     \u001b[32m0.9962\u001b[0m        \u001b[35m0.3039\u001b[0m       \u001b[31m0.9962\u001b[0m        \u001b[94m0.3090\u001b[0m     +  312.0275\n",
      "      4     0.9844     0.9962        0.3041       0.9962        0.3092        312.9366\n",
      "      5     0.9846     0.9962        \u001b[35m0.3031\u001b[0m       0.9962        \u001b[94m0.3088\u001b[0m        313.3549\n",
      "      6     \u001b[36m0.9847\u001b[0m     0.9962        \u001b[35m0.3020\u001b[0m       0.9962        \u001b[94m0.3086\u001b[0m     +  313.3883\n",
      "      7     0.9842     0.9961        0.3034       0.9961        0.3096        313.3217\n",
      "      8     0.9844     0.9962        \u001b[35m0.3018\u001b[0m       0.9962        0.3092        312.9318\n",
      "      9     0.9837     0.9961        0.3021       0.9961        0.3096        309.0600\n",
      "     10     0.9835     0.9961        \u001b[35m0.3003\u001b[0m       0.9961        0.3097        308.4158\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (d1): DownSample2x(\n",
       "      (0): Conv1d(1, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c1): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d2): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c2): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d3): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c3): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d4): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c4): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d5): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c5): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d6): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c6): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cls): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.0001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    criterion=F1Loss,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model1', fn_prefix='f1')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.initialize() \n",
    "net.load_params(f_params='03_model1/params.pt')\n",
    "net.partial_fit(traval_tra_features, traval_tra_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9430\u001b[0m     \u001b[32m0.9858\u001b[0m        \u001b[35m0.0340\u001b[0m       \u001b[31m0.9858\u001b[0m        \u001b[94m0.0431\u001b[0m     +  304.3791\n",
      "      2     \u001b[36m0.9772\u001b[0m     \u001b[32m0.9938\u001b[0m        \u001b[35m0.0204\u001b[0m       \u001b[31m0.9938\u001b[0m        \u001b[94m0.0205\u001b[0m     +  303.8527\n",
      "      3     0.9751     0.9931        \u001b[35m0.0176\u001b[0m       0.9931        0.0216        305.1009\n",
      "      4     0.9770     \u001b[32m0.9941\u001b[0m        \u001b[35m0.0160\u001b[0m       \u001b[31m0.9941\u001b[0m        \u001b[94m0.0194\u001b[0m        303.8466\n",
      "      5     \u001b[36m0.9792\u001b[0m     \u001b[32m0.9948\u001b[0m        \u001b[35m0.0150\u001b[0m       \u001b[31m0.9948\u001b[0m        \u001b[94m0.0163\u001b[0m     +  300.3223\n",
      "      6     \u001b[36m0.9832\u001b[0m     \u001b[32m0.9958\u001b[0m        \u001b[35m0.0143\u001b[0m       \u001b[31m0.9958\u001b[0m        \u001b[94m0.0145\u001b[0m     +  302.7430\n",
      "      7     0.9830     0.9957        \u001b[35m0.0136\u001b[0m       0.9957        0.0149        302.2970\n",
      "      8     \u001b[36m0.9833\u001b[0m     0.9957        \u001b[35m0.0130\u001b[0m       0.9957        \u001b[94m0.0140\u001b[0m     +  303.8143\n",
      "      9     0.9824     0.9956        \u001b[35m0.0126\u001b[0m       0.9956        0.0152        306.9870\n",
      "     10     \u001b[36m0.9834\u001b[0m     \u001b[32m0.9959\u001b[0m        \u001b[35m0.0121\u001b[0m       \u001b[31m0.9959\u001b[0m        0.0146     +  312.0679\n",
      "     11     \u001b[36m0.9837\u001b[0m     \u001b[32m0.9960\u001b[0m        \u001b[35m0.0117\u001b[0m       \u001b[31m0.9960\u001b[0m        \u001b[94m0.0138\u001b[0m     +  310.1914\n",
      "     12     0.9814     0.9955        \u001b[35m0.0112\u001b[0m       0.9955        0.0165        309.6221\n",
      "     13     0.9824     0.9957        \u001b[35m0.0108\u001b[0m       0.9957        0.0145        311.0316\n",
      "     14     0.9833     0.9958        \u001b[35m0.0106\u001b[0m       0.9958        0.0144        311.4288\n",
      "     15     0.9828     0.9958        \u001b[35m0.0100\u001b[0m       0.9958        0.0149        306.6665\n",
      "     16     0.9833     0.9959        \u001b[35m0.0096\u001b[0m       0.9959        0.0148        308.5779\n",
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9850\u001b[0m     \u001b[32m0.9963\u001b[0m        \u001b[35m0.3052\u001b[0m       \u001b[31m0.9963\u001b[0m        \u001b[94m0.3092\u001b[0m     +  315.5799\n",
      "      2     0.9848     0.9962        \u001b[35m0.3041\u001b[0m       0.9962        \u001b[94m0.3084\u001b[0m        316.8242\n",
      "      3     0.9846     0.9962        \u001b[35m0.3025\u001b[0m       0.9962        \u001b[94m0.3083\u001b[0m        314.7916\n",
      "      4     0.9846     0.9962        0.3026       0.9962        0.3084        311.7821\n",
      "      5     0.9846     0.9962        \u001b[35m0.3019\u001b[0m       0.9962        0.3084        312.1261\n",
      "      6     0.9850     \u001b[32m0.9963\u001b[0m        \u001b[35m0.3011\u001b[0m       \u001b[31m0.9963\u001b[0m        0.3084        313.5587\n",
      "      7     0.9847     0.9963        \u001b[35m0.3001\u001b[0m       0.9963        0.3086        312.7350\n",
      "      8     0.9844     0.9962        0.3006       0.9962        0.3091        312.4648\n",
      "      9     0.9843     0.9962        0.3005       0.9962        0.3087        314.0565\n",
      "     10     0.9840     0.9961        \u001b[35m0.2997\u001b[0m       0.9961        0.3086        314.8614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (d1): DownSample2x(\n",
       "      (0): Conv1d(1, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c1): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d2): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c2): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d3): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c3): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d4): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c4): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d5): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c5): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d6): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c6): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cls): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=16,\n",
    "    lr=0.001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model2')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.fit(traval_tra_features, traval_tra_targets)\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.0001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    criterion=F1Loss,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model2', fn_prefix='f1')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.initialize() \n",
    "net.load_params(f_params='03_model2/params.pt')\n",
    "net.partial_fit(traval_tra_features, traval_tra_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.0797\u001b[0m     \u001b[32m0.1245\u001b[0m        \u001b[35m0.0345\u001b[0m       \u001b[31m0.1245\u001b[0m        \u001b[94m8.5422\u001b[0m     +  308.1514\n",
      "      2     \u001b[36m0.9768\u001b[0m     \u001b[32m0.9937\u001b[0m        \u001b[35m0.0203\u001b[0m       \u001b[31m0.9937\u001b[0m        \u001b[94m0.0214\u001b[0m     +  305.9702\n",
      "      3     \u001b[36m0.9777\u001b[0m     \u001b[32m0.9945\u001b[0m        \u001b[35m0.0176\u001b[0m       \u001b[31m0.9945\u001b[0m        \u001b[94m0.0177\u001b[0m     +  303.4543\n",
      "      4     \u001b[36m0.9804\u001b[0m     \u001b[32m0.9951\u001b[0m        \u001b[35m0.0164\u001b[0m       \u001b[31m0.9951\u001b[0m        \u001b[94m0.0164\u001b[0m     +  304.3938\n",
      "      5     \u001b[36m0.9807\u001b[0m     \u001b[32m0.9951\u001b[0m        \u001b[35m0.0151\u001b[0m       \u001b[31m0.9951\u001b[0m        \u001b[94m0.0162\u001b[0m     +  303.5369\n",
      "      6     0.9801     0.9948        \u001b[35m0.0142\u001b[0m       0.9948        0.0180        306.5462\n",
      "      7     \u001b[36m0.9834\u001b[0m     \u001b[32m0.9958\u001b[0m        \u001b[35m0.0137\u001b[0m       \u001b[31m0.9958\u001b[0m        \u001b[94m0.0145\u001b[0m     +  307.2421\n",
      "      8     0.9824     0.9956        \u001b[35m0.0130\u001b[0m       0.9956        0.0155        306.8863\n",
      "      9     \u001b[36m0.9837\u001b[0m     \u001b[32m0.9958\u001b[0m        \u001b[35m0.0126\u001b[0m       \u001b[31m0.9958\u001b[0m        \u001b[94m0.0140\u001b[0m     +  304.9817\n",
      "     10     0.9782     0.9947        \u001b[35m0.0122\u001b[0m       0.9947        0.0163        304.5655\n",
      "     11     0.9813     0.9951        \u001b[35m0.0117\u001b[0m       0.9951        0.0181        303.0291\n",
      "     12     0.9830     0.9957        \u001b[35m0.0114\u001b[0m       0.9957        0.0146        305.7888\n",
      "     13     0.9811     0.9952        \u001b[35m0.0108\u001b[0m       0.9952        0.0166        304.7960\n",
      "     14     0.9820     0.9955        \u001b[35m0.0106\u001b[0m       0.9955        0.0155        303.4206\n",
      "     15     \u001b[36m0.9841\u001b[0m     \u001b[32m0.9960\u001b[0m        \u001b[35m0.0103\u001b[0m       \u001b[31m0.9960\u001b[0m        0.0143     +  302.9668\n",
      "     16     0.9840     \u001b[32m0.9960\u001b[0m        \u001b[35m0.0099\u001b[0m       \u001b[31m0.9960\u001b[0m        0.0159        303.6968\n",
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9850\u001b[0m     \u001b[32m0.9963\u001b[0m        \u001b[35m0.3037\u001b[0m       \u001b[31m0.9963\u001b[0m        \u001b[94m0.3087\u001b[0m     +  309.5140\n",
      "      2     0.9842     0.9961        \u001b[35m0.3023\u001b[0m       0.9961        \u001b[94m0.3086\u001b[0m        309.4594\n",
      "      3     0.9847     0.9961        \u001b[35m0.3016\u001b[0m       0.9961        \u001b[94m0.3085\u001b[0m        308.0231\n",
      "      4     0.9842     0.9961        \u001b[35m0.3003\u001b[0m       0.9961        0.3088        313.7334\n",
      "      5     0.9840     0.9961        \u001b[35m0.2998\u001b[0m       0.9961        0.3090        312.1635\n",
      "      6     0.9843     0.9962        0.3007       0.9962        0.3088        310.5944\n",
      "      7     0.9841     0.9961        0.3001       0.9961        0.3092        309.2206\n",
      "      8     0.9840     0.9961        \u001b[35m0.2985\u001b[0m       0.9961        0.3089        308.3193\n",
      "      9     0.9841     0.9961        \u001b[35m0.2984\u001b[0m       0.9961        0.3089        309.7007\n",
      "     10     0.9832     0.9960        \u001b[35m0.2983\u001b[0m       0.9960        0.3095        308.4388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (d1): DownSample2x(\n",
       "      (0): Conv1d(1, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c1): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d2): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c2): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d3): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c3): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d4): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c4): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d5): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c5): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d6): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c6): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cls): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=16,\n",
    "    lr=0.001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model3')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.fit(traval_tra_features, traval_tra_targets)\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.0001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    criterion=F1Loss,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model3', fn_prefix='f1')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.initialize() \n",
    "net.load_params(f_params='03_model3/params.pt')\n",
    "net.partial_fit(traval_tra_features, traval_tra_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amax/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:104: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9670\u001b[0m     \u001b[32m0.9916\u001b[0m        \u001b[35m0.0342\u001b[0m       \u001b[31m0.9916\u001b[0m        \u001b[94m0.0258\u001b[0m     +  303.3747\n",
      "      2     \u001b[36m0.9746\u001b[0m     \u001b[32m0.9936\u001b[0m        \u001b[35m0.0208\u001b[0m       \u001b[31m0.9936\u001b[0m        \u001b[94m0.0211\u001b[0m     +  302.1407\n",
      "      3     \u001b[36m0.9798\u001b[0m     \u001b[32m0.9948\u001b[0m        \u001b[35m0.0178\u001b[0m       \u001b[31m0.9948\u001b[0m        \u001b[94m0.0176\u001b[0m     +  305.9477\n",
      "      4     \u001b[36m0.9811\u001b[0m     \u001b[32m0.9953\u001b[0m        \u001b[35m0.0163\u001b[0m       \u001b[31m0.9953\u001b[0m        \u001b[94m0.0154\u001b[0m     +  307.9575\n",
      "      5     0.9809     \u001b[32m0.9953\u001b[0m        \u001b[35m0.0150\u001b[0m       \u001b[31m0.9953\u001b[0m        \u001b[94m0.0150\u001b[0m        307.7735\n",
      "      6     0.9808     0.9952        \u001b[35m0.0145\u001b[0m       0.9952        0.0153        304.0878\n",
      "      7     0.9795     0.9951        \u001b[35m0.0137\u001b[0m       0.9951        0.0162        303.3571\n",
      "      8     \u001b[36m0.9816\u001b[0m     \u001b[32m0.9956\u001b[0m        \u001b[35m0.0130\u001b[0m       \u001b[31m0.9956\u001b[0m        \u001b[94m0.0150\u001b[0m     +  303.7928\n",
      "      9     \u001b[36m0.9826\u001b[0m     \u001b[32m0.9956\u001b[0m        \u001b[35m0.0126\u001b[0m       \u001b[31m0.9956\u001b[0m        0.0155     +  304.1707\n",
      "     10     0.9808     0.9953        \u001b[35m0.0120\u001b[0m       0.9953        0.0163        303.5776\n",
      "     11     0.9820     0.9955        \u001b[35m0.0118\u001b[0m       0.9955        0.0154        302.3708\n",
      "     12     \u001b[36m0.9827\u001b[0m     \u001b[32m0.9958\u001b[0m        \u001b[35m0.0113\u001b[0m       \u001b[31m0.9958\u001b[0m        \u001b[94m0.0142\u001b[0m     +  302.5860\n",
      "     13     0.9824     0.9954        \u001b[35m0.0109\u001b[0m       0.9954        0.0163        301.6305\n",
      "     14     0.9816     0.9956        \u001b[35m0.0104\u001b[0m       0.9956        0.0151        302.2446\n",
      "     15     0.9778     0.9941        \u001b[35m0.0102\u001b[0m       0.9941        0.0203        303.9300\n",
      "     16     \u001b[36m0.9836\u001b[0m     \u001b[32m0.9959\u001b[0m        \u001b[35m0.0097\u001b[0m       \u001b[31m0.9959\u001b[0m        0.0147     +  305.1647\n",
      "  epoch    macrof1    microf1    train_loss    valid_acc    valid_loss    cp       dur\n",
      "-------  ---------  ---------  ------------  -----------  ------------  ----  --------\n",
      "      1     \u001b[36m0.9843\u001b[0m     \u001b[32m0.9961\u001b[0m        \u001b[35m0.3030\u001b[0m       \u001b[31m0.9961\u001b[0m        \u001b[94m0.3099\u001b[0m     +  309.9714\n",
      "      2     \u001b[36m0.9844\u001b[0m     0.9961        \u001b[35m0.3012\u001b[0m       0.9961        \u001b[94m0.3092\u001b[0m     +  310.2267\n",
      "      3     0.9842     0.9961        \u001b[35m0.3003\u001b[0m       0.9961        0.3093        309.6704\n",
      "      4     \u001b[36m0.9850\u001b[0m     \u001b[32m0.9962\u001b[0m        \u001b[35m0.2995\u001b[0m       \u001b[31m0.9962\u001b[0m        \u001b[94m0.3087\u001b[0m     +  308.5563\n",
      "      5     0.9845     0.9962        0.3004       0.9962        0.3094        307.8314\n",
      "      6     0.9840     0.9960        \u001b[35m0.2989\u001b[0m       0.9960        0.3091        307.8737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=MyModule(\n",
       "    (d1): DownSample2x(\n",
       "      (0): Conv1d(1, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c1): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d2): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c2): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d3): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c3): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d4): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c4): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d5): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c5): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (d6): DownSample2x(\n",
       "      (0): Conv1d(64, 64, kernel_size=(2,), stride=(2,))\n",
       "      (1): ReLU(inplace=True)\n",
       "    )\n",
       "    (c6): ResConv1d(\n",
       "      (cal): Sequential(\n",
       "        (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU()\n",
       "        (3): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
       "        (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (se): SELayer(\n",
       "        (avg_pool): AdaptiveAvgPool1d(output_size=1)\n",
       "        (fc): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): PReLU(num_parameters=1)\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (3): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (conv): Conv1d(64, 64, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (cls): Linear(in_features=2560, out_features=3, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=16,\n",
    "    lr=0.001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model4')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.fit(traval_tra_features, traval_tra_targets)\n",
    "\n",
    "net = NeuralNetClassifier(\n",
    "    MyModule,\n",
    "    max_epochs=10,\n",
    "    lr=0.0001,\n",
    "    batch_size=128,\n",
    "    optimizer=Adam,\n",
    "    iterator_train__shuffle=True,\n",
    "    criterion=F1Loss,\n",
    "    train_split=predefined_split(valid_ds),\n",
    "    callbacks=[EpochScoring(macrof1, use_caching=True, lower_is_better=False),\n",
    "               EpochScoring(microf1, use_caching=True, lower_is_better=False),\n",
    "               Checkpoint(monitor='macrof1_best', dirname='03_model4', fn_prefix='f1')],\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "net.initialize() \n",
    "net.load_params(f_params='03_model4/params.pt')\n",
    "net.partial_fit(traval_tra_features, traval_tra_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
